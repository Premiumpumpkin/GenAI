{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Author: Antonio Cima\n",
        "\n",
        "Purpose: To Generate bedroom images using the lsun dataset using a Generative Adversarial Network"
      ],
      "metadata": {
        "id": "scaMOBgYmNF2"
      },
      "id": "scaMOBgYmNF2"
    },
    {
      "cell_type": "markdown",
      "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
      "metadata": {
        "id": "b076bd1a-b236-4fbc-953d-8295b25122ae"
      },
      "source": [
        "Setting Up Paramaters and import statements to ready our data\n",
        "\n",
        "We also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
      "metadata": {
        "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1\n",
        "BATCH_SIZE = 256\n",
        "Z_DIM = 100\n",
        "\n",
        "# This took me 30 minutes on TPU but author suggests 300!\n",
        "EPOCHS = 50\n",
        "\n",
        "LOAD_MODEL = False\n",
        "ADAM_BETA_1 = 0.5\n",
        "ADAM_BETA_2 = 0.999\n",
        "LEARNING_RATE = 0.0002\n",
        "NOISE_PARAM = 0.1\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d jhoward/lsun_bedroom -p /content/drive/MyDrive/lsun_bedroom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    utils,\n",
        "    metrics,\n",
        "    optimizers,\n",
        "    utils,\n",
        ")\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):#to prevent constant mounting\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Drive is already mounted.\")\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "zip_file_path = '/content/drive/MyDrive/lsun_bedroom/lsun_bedroom.zip'\n",
        "extract_to = '/content'\n",
        "\n",
        "# Extract the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "def get_jpg_paths(root_dir):\n",
        "  jpg_paths = []\n",
        "  images = []\n",
        "  for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for filename in filenames:\n",
        "      if filename.endswith('.jpg'):\n",
        "        jpg_paths.append(os.path.join(dirpath, filename))\n",
        "  return jpg_paths\n",
        "\n",
        "root_dir = '/content/data0'\n",
        "jpg_file_paths = get_jpg_paths(root_dir)\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=CHANNELS)\n",
        "    img = tf.image.resize(img, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    img = (tf.cast(img, \"float32\") - 127.5) / 127.5\n",
        "    return img\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(jpg_file_paths) #Gathering the dataset (images) to be trained with.\n",
        "dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "images = list(dataset.as_numpy_iterator())\n",
        "\n",
        "print(f\"Processed and appended {len(images)} images.\")\n",
        "\n",
        "# Print the number of files found and a few sample paths\n",
        "print(f\"Found {len(jpg_file_paths)} .jpg files.\")\n",
        "print(\"Sample paths:\")\n",
        "\n",
        "\n",
        "\n",
        "train = dataset.map(lambda x: x) #just needed to get the dataset into train so I figured this would work without any harm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
      "metadata": {
        "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5"
      },
      "source": [
        "## 2. Build the GAN <a name=\"build\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ed493725-488b-4390-8c64-661f3b97a632",
      "metadata": {
        "id": "ed493725-488b-4390-8c64-661f3b97a632"
      },
      "outputs": [],
      "source": [
        "def make_generator_model(): #creating the generator model\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(8*8*512, use_bias=False, input_shape=(Z_DIM,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((8, 8, 512)))\n",
        "    assert model.output_shape == (None, 8, 8, 512) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 256)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 16, 16, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 32, 32, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(CHANNELS, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 64, 64, CHANNELS)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "class DCGAN(models.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(DCGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer):\n",
        "        super(DCGAN, self).compile()\n",
        "        self.loss_fn = losses.BinaryCrossentropy()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
        "        self.d_real_acc_metric = metrics.BinaryAccuracy(name=\"d_real_acc\")\n",
        "        self.d_fake_acc_metric = metrics.BinaryAccuracy(name=\"d_fake_acc\")\n",
        "        self.d_acc_metric = metrics.BinaryAccuracy(name=\"d_acc\")\n",
        "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
        "        self.g_acc_metric = metrics.BinaryAccuracy(name=\"g_acc\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.d_loss_metric,\n",
        "            self.d_real_acc_metric,\n",
        "            self.d_fake_acc_metric,\n",
        "            self.d_acc_metric,\n",
        "            self.g_loss_metric,\n",
        "            self.g_acc_metric,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim)\n",
        "        )\n",
        "\n",
        "        # Train the discriminator on fake images\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            generated_images = self.generator(\n",
        "                random_latent_vectors, training=True\n",
        "            )\n",
        "            real_predictions = self.discriminator(real_images, training=True)\n",
        "            fake_predictions = self.discriminator(generated_images, training=True)\n",
        "\n",
        "            real_labels = tf.ones_like(real_predictions)\n",
        "            real_noisy_labels = real_labels + NOISE_PARAM * tf.random.uniform(\n",
        "                tf.shape(real_predictions)\n",
        "            )\n",
        "            fake_labels = tf.zeros_like(fake_predictions)\n",
        "            fake_noisy_labels = fake_labels - NOISE_PARAM * tf.random.uniform(\n",
        "                tf.shape(fake_predictions)\n",
        "            )\n",
        "\n",
        "            d_real_loss = self.loss_fn(real_noisy_labels, real_predictions)\n",
        "            d_fake_loss = self.loss_fn(fake_noisy_labels, fake_predictions)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
        "\n",
        "            g_loss = self.loss_fn(real_labels, fake_predictions)\n",
        "\n",
        "        gradients_of_discriminator = disc_tape.gradient(\n",
        "            d_loss, self.discriminator.trainable_variables\n",
        "        )\n",
        "        gradients_of_generator = gen_tape.gradient(\n",
        "            g_loss, self.generator.trainable_variables\n",
        "        )\n",
        "\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(gradients_of_discriminator, self.discriminator.trainable_variables)\n",
        "        )\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gradients_of_generator, self.generator.trainable_variables)\n",
        "        )\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.d_real_acc_metric.update_state(real_labels, real_predictions)\n",
        "        self.d_fake_acc_metric.update_state(fake_labels, fake_predictions)\n",
        "        self.d_acc_metric.update_state(\n",
        "            [real_labels, fake_labels], [real_predictions, fake_predictions]\n",
        "        )\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        self.g_acc_metric.update_state(real_labels, fake_predictions)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b14665-4359-447b-be58-3fd58ba69084",
      "metadata": {
        "id": "35b14665-4359-447b-be58-3fd58ba69084"
      },
      "source": [
        "We create an object of the GAN to then train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349865fe-ffbe-450e-97be-043ae1740e78",
      "metadata": {
        "id": "349865fe-ffbe-450e-97be-043ae1740e78"
      },
      "outputs": [],
      "source": [
        "# Create a DCGAN\n",
        "dcgan = DCGAN(\n",
        "    discriminator=make_discriminator_model(), generator=make_generator_model(), latent_dim=Z_DIM\n",
        ")\n",
        "\n",
        "dcgan.compile(\n",
        "    d_optimizer=optimizers.Adam(\n",
        "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
        "    ),\n",
        "    g_optimizer=optimizers.Adam(\n",
        "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
        "    ),\n",
        ")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_img, latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(self.num_img, self.latent_dim)\n",
        "        )\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images = generated_images * 127.5 + 127.5\n",
        "        generated_images = generated_images.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally allowing the generator to train itself using the generator and discriminator."
      ],
      "metadata": {
        "id": "NVNWipwZjzaW"
      },
      "id": "NVNWipwZjzaW"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a8913a77-f472-4008-9039-dba00e6db980",
      "metadata": {
        "id": "a8913a77-f472-4008-9039-dba00e6db980"
      },
      "outputs": [],
      "source": [
        "dcgan.fit(train, epochs=EPOCHS, callbacks=[ImageGenerator(num_img=16, latent_dim=Z_DIM)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26999087-0e85-4ddf-ba5f-13036466fce7",
      "metadata": {
        "id": "26999087-0e85-4ddf-ba5f-13036466fce7"
      },
      "source": [
        "Now we begin to generate new images using the training set we just used!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5e43c0-ef06-4d32-acf6-09f00cf2fa9c",
      "metadata": {
        "id": "5e5e43c0-ef06-4d32-acf6-09f00cf2fa9c"
      },
      "outputs": [],
      "source": [
        "# Sample some points in the latent space, from the standard normal distribution\n",
        "grid_width, grid_height = (10, 3)\n",
        "z_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))\n",
        "\n",
        "# Decode the sampled points\n",
        "reconstructions = dcgan.generator.predict(z_sample)\n",
        "\n",
        "# Draw a plot of decoded images\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "# Output the grid of faces\n",
        "for i in range(grid_width * grid_height):\n",
        "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A couple of blocks of code to look between both generated and existing images to then compare the two to see how similar they are."
      ],
      "metadata": {
        "id": "nKfJAw-2j3wD"
      },
      "id": "nKfJAw-2j3wD"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "59bfd4e4-7fdc-488a-86df-2c131c904803",
      "metadata": {
        "id": "59bfd4e4-7fdc-488a-86df-2c131c904803"
      },
      "outputs": [],
      "source": [
        "def compare_images(img1, img2):\n",
        "    return np.mean(np.abs(img1 - img2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b568995a-d4ad-478c-98b2-d9a1cdb9e841",
      "metadata": {
        "id": "b568995a-d4ad-478c-98b2-d9a1cdb9e841"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "for i in train.as_numpy_iterator():\n",
        "    all_data.extend(i)\n",
        "all_data = np.array(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c4b5bb1-3581-49b3-81ce-920400d6f3f7",
      "metadata": {
        "id": "7c4b5bb1-3581-49b3-81ce-920400d6f3f7"
      },
      "outputs": [],
      "source": [
        "r, c = 3, 5\n",
        "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
        "fig.suptitle(\"Generated images\", fontsize=20)\n",
        "\n",
        "noise = np.random.normal(size=(r * c, Z_DIM))\n",
        "gen_imgs = dcgan.generator.predict(noise)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i, j].imshow(gen_imgs[cnt], cmap=\"gray_r\")\n",
        "        axs[i, j].axis(\"off\")\n",
        "        cnt += 1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we then compare The most similar images to the dataset we trained!"
      ],
      "metadata": {
        "id": "z8oTaQxqPTy5"
      },
      "id": "z8oTaQxqPTy5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51923e98-bf0e-4de4-948a-05147c486b72",
      "metadata": {
        "id": "51923e98-bf0e-4de4-948a-05147c486b72"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
        "fig.suptitle(\"Closest images in the training set\", fontsize=20)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        c_diff = 99999\n",
        "        c_img = None\n",
        "        for k_idx, k in enumerate(all_data):\n",
        "            diff = compare_images(gen_imgs[cnt], k)\n",
        "            if diff < c_diff:\n",
        "                c_img = np.copy(k)\n",
        "                c_diff = diff\n",
        "        axs[i, j].imshow(c_img, cmap=\"gray_r\")\n",
        "        axs[i, j].axis(\"off\")\n",
        "        cnt += 1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concluding thoughts:\n",
        "\n",
        "The model was able to generate a very diverse set of images, I could see the potential in using GAN in order to mass train a ton of images (even though it is lengthy). I feel as if in order to reduce time spent training and generating images, we could up the random noise increment; we are already looking at a lot of images already, if we allow the AI to be a lot more hands on, it could yield us interesting and faster results!\n",
        "\n",
        "PS. If you are looking for generated images, I accdidentally ran google colab again and it deleted all the photos; it's way too late for me to be trying to run through it again so I can just give you the code!"
      ],
      "metadata": {
        "id": "OD9MippaPX-E"
      },
      "id": "OD9MippaPX-E"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}